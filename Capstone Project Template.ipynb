{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importing Immigration dataset:\n",
    "*Immigration dataset if quite large in size so its better to use **Apache Spark** to read the files in this case.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.5 ms, sys: 23.2 ms, total: 61.6 ms\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_immig =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "#df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(cicid=6.0, i94yr=2016.0, i94mon=4.0, i94cit=692.0, i94res=692.0, i94port='XXX', arrdate=20573.0, i94mode=None, i94addr=None, depdate=None, i94bir=37.0, i94visa=2.0, count=1.0, dtadfile=None, visapost=None, occup=None, entdepa='T', entdepd=None, entdepu='U', matflag=None, biryear=1979.0, dtaddto='10282016', gender=None, insnum=None, airline=None, admnum=1897628485.0, fltno=None, visatype='B2'),\n",
       " Row(cicid=7.0, i94yr=2016.0, i94mon=4.0, i94cit=254.0, i94res=276.0, i94port='ATL', arrdate=20551.0, i94mode=1.0, i94addr='AL', depdate=None, i94bir=25.0, i94visa=3.0, count=1.0, dtadfile='20130811', visapost='SEO', occup=None, entdepa='G', entdepd=None, entdepu='Y', matflag=None, biryear=1991.0, dtaddto='D/S', gender='M', insnum=None, airline=None, admnum=3736796330.0, fltno='00296', visatype='F1')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immig.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Importing world_temperature dataset:\n",
    "*World temperature dataset if quite large in size so its better to use **Apache Spark** to read the files in this case.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Read in the data here\n",
    "# df_temp=pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.79 ms, sys: 103 µs, total: 2.89 ms\n",
      "Wall time: 2.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_temp=spark.read.format('csv').option('header','True').load('../../data2/GlobalLandTemperaturesByCity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Importing airport_code dataset:\n",
    "*airport_code dataset is not that much large in size its better to use **Pandas** to read the files in this case.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "df_port=pd.read_csv('airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                  name  elevation_ft continent  \\\n",
       "0   00A       heliport     Total Rf Heliport          11.0       NaN   \n",
       "1  00AA  small_airport  Aero B Ranch Airport        3435.0       NaN   \n",
       "\n",
       "  iso_country iso_region municipality gps_code iata_code local_code  \\\n",
       "0          US      US-PA     Bensalem      00A       NaN        00A   \n",
       "1          US      US-KS        Leoti     00AA       NaN       00AA   \n",
       "\n",
       "                          coordinates  \n",
       "0  -74.93360137939453, 40.07080078125  \n",
       "1              -101.473911, 38.704022  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51294</th>\n",
       "      <td>VOMM</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Chennai International Airport</td>\n",
       "      <td>52.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN-TN</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>VOMM</td>\n",
       "      <td>MAA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.16929626464844, 12.990005493164062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ident           type                           name  elevation_ft  \\\n",
       "51294  VOMM  large_airport  Chennai International Airport          52.0   \n",
       "\n",
       "      continent iso_country iso_region municipality gps_code iata_code  \\\n",
       "51294        AS          IN      IN-TN      Chennai     VOMM       MAA   \n",
       "\n",
       "      local_code                            coordinates  \n",
       "51294        NaN  80.16929626464844, 12.990005493164062  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port.query(\"iata_code=='MAA'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Importing us_cities_demographics dataset:\n",
    "*us_cities_demographics dataset is not that much large in size its better to use **Pandas** to read the files in this case.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "df_demog=pd.read_csv('us-cities-demographics.csv',delimiter=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Exploring Immigration dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns: 28\n",
      "Number of Rows: 3096313\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "print(\"Number of Columns: {}\".format(len(df_immig.columns)))\n",
    "print(\"Number of Rows: {}\".format(df_immig.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates value\n",
    "df_immig=df_immig.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 3096313\n"
     ]
    }
   ],
   "source": [
    "# Number of rows after removing duplicates\n",
    "print(\"Number of Rows: {}\".format(df_immig.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------+-------+------------------+------------------+-------+-----------------+------------------+------------------+-----------------+------------------+-------------------+-------+--------------------+--------+-----------------+-------+-------+-------+-------+------------------+------------------+-------+-----------------+------------------+--------------------+------------------+--------+\n",
      "|summary|            cicid|  i94yr| i94mon|            i94cit|            i94res|i94port|          arrdate|           i94mode|           i94addr|          depdate|            i94bir|            i94visa|  count|            dtadfile|visapost|            occup|entdepa|entdepd|entdepu|matflag|           biryear|           dtaddto| gender|           insnum|           airline|              admnum|             fltno|visatype|\n",
      "+-------+-----------------+-------+-------+------------------+------------------+-------+-----------------+------------------+------------------+-----------------+------------------+-------------------+-------+--------------------+--------+-----------------+-------+-------+-------+-------+------------------+------------------+-------+-----------------+------------------+--------------------+------------------+--------+\n",
      "|  count|          3096313|3096313|3096313|           3096313|           3096313|3096313|          3096313|           3096074|           2943721|          2953856|           3095511|            3096313|3096313|             3096312| 1215063|             8126|3096075|2957884|    392|2957884|           3095511|           3095836|2682044|           113708|           3012686|             3096313|           3076764| 3096313|\n",
      "|   mean|3078651.879075533| 2016.0|    4.0| 304.9069344733559|303.28381949757664|   null|20559.84854179794|1.0736897761487614|51.652482269503544|20573.95283554784|41.767614458485205| 1.8453925685161674|    1.0|2.0160424766168267E7|   999.0|          885.675|   null|   null|   null|   null|1974.2323855415148| 8291120.333841449|   null|4131.050016327899|59.477601493233784|  7.0828850111112E10|1360.2463696420555|    null|\n",
      "| stddev|1763278.099749879|    0.0|    0.0|210.02688853063296|208.58321292788838|   null|8.777339475017895|0.5158963131657227| 42.97906231370985|29.35696848166126|  17.4202605345882|0.39839102005409555|    0.0|   50.01513446847667|     0.0|264.6551105950962|   null|   null|   null|   null|17.420260534588213|1656502.4244925082|   null|8821.743471773649|172.63339952061744|2.215441594755766E10| 5852.676345633777|    null|\n",
      "|    min|              6.0| 2016.0|    4.0|             101.0|             101.0|    5KE|          20545.0|               1.0|                ..|          15176.0|              -3.0|                1.0|    1.0|            20130811|     999|              049|      A|      D|      U|      M|            1902.0|          /   183D|      F|                0|               *FF|                 0.0|             00000|      B1|\n",
      "|    max|        6102785.0| 2016.0|    4.0|             999.0|             760.0|    YSL|          20574.0|               9.0|                ZU|          45427.0|             114.0|                3.0|    1.0|            20160919|     ZZZ|              WTR|      Z|      W|      Y|      M|            2019.0|               D/S|      X|           YM0167|                ZZ|      9.991556593E10|               ZZZ|      WT|\n",
      "+-------+-----------------+-------+-------+------------------+------------------+-------+-----------------+------------------+------------------+-----------------+------------------+-------------------+-------+--------------------+--------+-----------------+-------+-------+-------+-------+------------------+------------------+-------+-----------------+------------------+--------------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe\n",
    "df_immig.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Exploring world_temperature dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns: 7\n",
      "Number of Rows: 8599212\n"
     ]
    }
   ],
   "source": [
    "#Shape of the Dataset\n",
    "print(\"Number of Columns: {}\".format(len(df_temp.columns)))\n",
    "print(\"Number of Rows: {}\".format(df_temp.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Shape of the dataset\n",
    "df_temp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, dt: string, AverageTemperature: string, AverageTemperatureUncertainty: string, City: string, Country: string, Latitude: string, Longitude: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking missing values\n",
    "df_temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates Values\n",
    "df_port.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Exploring airport_code dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55075, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the dataset\n",
    "df_port.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "elevation_ft    48069 non-null float64\n",
      "continent       27356 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking missing values\n",
    "df_port.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates Values\n",
    "df_port.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Exploring us_cities_demographics dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the dataset\n",
    "df_demog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "df_demog.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "df_demog.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Star Schema:\n",
    "##### Dimension Tables:\n",
    "> 1. Immigrant Table\n",
    "    * Columns: gender, biryear, occup, i94bir\n",
    "##### Fact Table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here\n",
    "immigrant_table=df_immig.select(['gender','biryear','occup','i94bir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigrant_table.write.mode('overwrite').option('compression','snappy').parquet(\"immigrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark=spark.read.option('compression','snappy').parquet(\"immigrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns: 4\n",
      "Number of Rows: 3096313\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "print(\"Number of Columns: {}\".format(len(df_spark.columns)))\n",
    "print(\"Number of Rows: {}\".format(df_spark.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----+------+\n",
      "|gender|biryear|occup|i94bir|\n",
      "+------+-------+-----+------+\n",
      "|     M| 1954.0| null|  62.0|\n",
      "|     F| 1979.0| null|  37.0|\n",
      "|     F| 1997.0| null|  19.0|\n",
      "|     F| 1947.0| null|  69.0|\n",
      "|     M| 1971.0| null|  45.0|\n",
      "+------+-------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Data dictionary \n",
    "_Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Immigration Data:\n",
    "~~~\n",
    "  * cicid    -  \n",
    "  * i94yr    - 4 digit year\n",
    "  * i94mon   - Numeric month\n",
    "  * i94cit   - This format shows all the valid and invalid codes for processing\n",
    "  * i94res   - This format shows all the valid and invalid codes for processing\n",
    "  * i94port  - This format shows all the valid and invalid codes for processing\n",
    "  * arrdate  - is the Arrival Date in the USA. It is a SAS date numeric field that a \n",
    "               permament format has not been applied.  Please apply whichever date format \n",
    "               works for you.\n",
    "  * i94mode  - There are missing values as well as not reported (9)\n",
    "               \t1 = 'Air'\n",
    "                2 = 'Sea'\n",
    "                3 = 'Land'\n",
    "                9 = 'Not reported' ;   \n",
    "  * i94addr  - There is lots of invalid codes in this variable and the list below \n",
    "               shows what we have found to be valid, everything else goes into 'other'\n",
    "  * depdate  - is the Departure Date from the USA. It is a SAS date numeric field that \n",
    "               a permament format has not been applied.  Please apply whichever date format \n",
    "               works for you.\n",
    "  * i94bir   - Age of Respondent in Years\n",
    "  * i94visa  - Visa codes collapsed into three categories:\n",
    "               1. 1 = Business\n",
    "               2. 2 = Pleasure\n",
    "               3. 3 = Student\n",
    "  * count    - Used for summary statistics\n",
    "  * dtadfile - Character Date Field - Date added to I-94 Files\n",
    "  * visapost - Department of State where where Visa was issued\n",
    "  * occup    - Occupation that will be performed in U.S.\n",
    "  * entdepa  - Arrival Flag - admitted or paroled into the U.S.\n",
    "  * entdepd  - Departure Flag - Departed, lost I-94 or is deceased\n",
    "  * entdepu  - Update Flag - Either apprehended, overstayed, adjusted to perm residence\n",
    "  * matflag  - Match flag - Match of arrival and departure records\n",
    "  * biryear  - 4 digit year of birth\n",
    "  * dtaddto  - Character Date Field - Date to which admitted to U.S. (allowed to stay until)\n",
    "  * gender   - Non-immigrant sex\n",
    "  * insnum   - INS number\n",
    "  * airline  - Airline used to arrive in U.S.\n",
    "  * admnum   - Admission Number\n",
    "  * fltno    - Flight number of Airline used to arrive in U.S.\n",
    "  * visatype - Class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n",
    "  \n",
    " ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### World Temperature Data:\n",
    "```\n",
    "* dt\n",
    "* AverageTemperature\n",
    "* AverageTemperatureUncertainty\n",
    "* City\n",
    "* Country\n",
    "* Latitude\n",
    "* Longitude\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### U.S. City Demographic Data:\n",
    "```\n",
    "* City\n",
    "* State\n",
    "* Median Age\n",
    "* Male Population\n",
    "* Female Population\n",
    "* Total Population\n",
    "* Number of Veterans\n",
    "* Foreign-born\n",
    "* Average Household Size\n",
    "* State Code\n",
    "* Race\n",
    "* Count\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Airport Codes:\n",
    "```\n",
    "* ident         - \n",
    "* type          - Type of airport e.g. 'small_airport', 'medium_airport', 'large_airport' etc\n",
    "* name          - Airport full name.\n",
    "* elevation_ft  - Elevation of the port measured in feet.  \n",
    "* continent     - Continet code (e.g 'AS' for Asia,'NA' for North America)\n",
    "* iso_country   - Two letter ISO country code assigned by International Organization for Standardization\n",
    "* iso_region    - iso region code assigned by ISO.\n",
    "* municipality  - Locality Municipality.  \n",
    "* gps_code      - Global Positioning System code.\n",
    "* iata_code     - IATA(Internation Air Transport Association) airport code, also known as IATA \n",
    "                  location identifier is a three letter code assigned to airports around the world.         \n",
    "* local_code    - Similar to gps_code.\n",
    "* coordinates   - (x,y) co-ordinates of the location.\n",
    "```       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
